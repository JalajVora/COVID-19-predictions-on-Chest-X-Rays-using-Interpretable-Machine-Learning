<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Results</title>

<script src="site_libs/header-attrs-2.3/header-attrs.js"></script>
<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/yeti.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="site_libs/pagedtable-1.1/js/pagedtable.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 45px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 50px;
  margin-top: -50px;
}
.section h2 {
  padding-top: 50px;
  margin-top: -50px;
}
.section h3 {
  padding-top: 50px;
  margin-top: -50px;
}
.section h4 {
  padding-top: 50px;
  margin-top: -50px;
}
.section h5 {
  padding-top: 50px;
  margin-top: -50px;
}
.section h6 {
  padding-top: 50px;
  margin-top: -50px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">COVID-19 Prediction using Explainable Machine Learning</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="Exploratory-Data-Analysis.html">Exploratory Data Analysis</a>
</li>
<li>
  <a href="Classification.html">Classification</a>
</li>
<li>
  <a href="Results.html">Results</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Results</h1>

</div>


<p>     </p>
<div id="explanations" class="section level2">
<h2>Explanations</h2>
<p>Apart from prediction of positive and negative for COVID-19 cases from CXR images, we try providing an explanation of which areas of the image contributes towards the predicted results. Local interpretable model-agnostic explanations (LIME) <span class="citation">[<a href="#ref-ribeiro2016should" role="doc-biblioref">1</a>]</span> is a local surrogate model. That is instead of explaining the global prediction, it only explains the local prediction. Therefore once the predictions are available, the LIME model can be run, in hope that, the model finds the areas of the image that contributes most towards the prediction.</p>
<p>Given any(black box/transparent) model, the Lime model probes the model and gets the output any number of time(theoritically). Lime creates a data set consist of permutated samples of the images, and feed those images to the model and tries to predict what happens to the predictions for the permutated samples.</p>
<p>We initially ran our application, while feeding the whole image. However, as expected the areas where the lime model is trying to explain, is outside the intended region. For that reason, we give the model, the masked lungs image as input, while the other parts of the image is black. We thus, force the lime model to do any changes in the model on the intended area. This time, as expected the lime model focuses more on the parts of the lungs and thus gives a better performance.</p>
<center>
<p><img src="1-mask.png" alt="1-mask.png" /> <img src="1.jpgtmp.png" alt="1.jpgtmp.png" /> <img src="1.png" alt="1.png" /></p>
</center>
<p><strong>Parameters and settings:</strong> As a part of preprocessing of the images to be fed to the lime model, we do greyscaling of the image. While no resizing is done, the image is processed so that the 1 channel greyscaled masked image is fed to the LIME model.</p>
<p>Number of features to find is set to 10.</p>
<p>Only “positive” areas are marked in the explanation image.</p>
<hr />
</div>
<div id="benchmark-evaluation" class="section level2 tabset">
<h2 class="tabset">Benchmark Evaluation</h2>
<p><img src="Results_files/figure-html/accuracyplotmodel-1.png" width="672" /></p>
<p>In accordance to <span class="citation">[<a href="#ref-ozturk2020automated" role="doc-biblioref">2</a>]</span>, where in the author presented a network for detection of COVID-19 cases using Deep Neural Networks with X-Ray images.The paper presents a detailed comparison study of their network with respect to other models for COVID-19 detection, in terms of accuracy. The details of the data-set used is explained in the following paragraph.</p>
<p>The database was developed by <span class="citation">[<a href="#ref-cohen2020covid" role="doc-biblioref">3</a>]</span> using images from various sources. The database is constantly upgraded, as of now, the database content comprise of around “201” COVID-19 positive X-Ray images.There were no images, which represent X-Ray of normal lungs, hence we have used thousand healthy X-Ray images from our original database as negative class, which we have used to feed our original models.</p>
<p>In the following sections, we present the figures that are obtained by training the models with the same data-set that <span class="citation">[<a href="#ref-ozturk2020automated" role="doc-biblioref">2</a>]</span> used in his experiment followed by the comparison table :</p>
<div id="comparison-of-different-models" class="section level4">
<h4><span class="sub-header">Comparison of different models</span></h4>
<table>
<colgroup>
<col width="15%" />
<col width="13%" />
<col width="30%" />
<col width="32%" />
<col width="8%" />
</colgroup>
<thead>
<tr class="header">
<th>Study</th>
<th>Type Of Image</th>
<th>No. Of Cases</th>
<th>Method Used and Settin</th>
<th>Accuracy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Sethy and Behra</td>
<td>Chest X-ray</td>
<td>25 COVID-19(+) 25 COVID-19 (−)</td>
<td>ResNet50+ SVM</td>
<td>95.38</td>
</tr>
<tr class="even">
<td>Hemdan et al.</td>
<td>Chest X-ray</td>
<td>25 COVID-19(+) 25 Normal</td>
<td>COVIDX-Net</td>
<td>90.0</td>
</tr>
<tr class="odd">
<td>Narin et al.</td>
<td>Chest X-ray</td>
<td>50 COVID-19(+) 50 COVID-19 (−)</td>
<td>Deep CNN ResNet-50</td>
<td>98.0</td>
</tr>
<tr class="even">
<td>Ying et al.</td>
<td>Chest CT</td>
<td>777 COVID-19(+) 708 Healthy</td>
<td>DRE-Net</td>
<td>86.0</td>
</tr>
<tr class="odd">
<td>Wang et al.</td>
<td>Chest CT</td>
<td>195 COVID-19(+) 258 COVID-19(−)</td>
<td>M-Inception</td>
<td>82.9</td>
</tr>
<tr class="even">
<td>Zheng et al.</td>
<td>Chest CT</td>
<td>313 COVID-19(+) 229 COVID-19(−)</td>
<td>UNet+3D Deep Network</td>
<td>90.8</td>
</tr>
<tr class="odd">
<td>Our Study</td>
<td>Chest X-ray</td>
<td>1000 COVID-19(-) 201 COVID-19(+)</td>
<td>Decision Tree with RAW Data</td>
<td>90.03</td>
</tr>
<tr class="even">
<td>Our Study</td>
<td>Chest X-ray</td>
<td>1000 COVID-19(-) 201 COVID-19(+)</td>
<td>Decision Tree with Oversampled Data</td>
<td>69.05</td>
</tr>
<tr class="odd">
<td>Our Study</td>
<td>Chest X-ray</td>
<td>1000 COVID-19(-) 201 COVID-19(+)</td>
<td>Random Forest with RAW Data</td>
<td>91.69</td>
</tr>
<tr class="even">
<td>Our Study</td>
<td>Chest X-ray</td>
<td>1000 COVID-19(-) 201 COVID-19(+)</td>
<td>Random Forest with Oversampled Data</td>
<td>79.17</td>
</tr>
<tr class="odd">
<td>Our Study</td>
<td>Chest X-ray</td>
<td>1000 COVID-19(-) 201 COVID-19(+)</td>
<td>kNN with RAW Data</td>
<td>90.62</td>
</tr>
<tr class="even">
<td>Our Study</td>
<td>Chest X-ray</td>
<td>1000 COVID-19(-) 201 COVID-19(+)</td>
<td>Logistic Regression with RAW Data</td>
<td>90.34</td>
</tr>
<tr class="odd">
<td>Our Study</td>
<td>Chest X-ray</td>
<td>1000 COVID-19(-) 201 COVID-19(+)</td>
<td>Naive Bayes with RAW Data</td>
<td>87.0</td>
</tr>
<tr class="even">
<td>Our Study</td>
<td>Chest X-ray</td>
<td>1000 COVID-19(-) 201 COVID-19(+)</td>
<td>SVM with Oversampled Data</td>
<td>54.73</td>
</tr>
</tbody>
</table>
<hr />
</div>
<div id="random-forest" class="section level3">
<h3>Random Forest</h3>
<pre class="r"><code># Confusion Matrix and Statistics
# 
#           Reference
# Prediction   0   1
#          0 245  18
#          1   7  31
#                                           
#               Accuracy : 0.9169          
#                  95% CI : (0.8798, 0.9455)
#     No Information Rate : 0.8372          
#     P-Value [Acc &gt; NIR] : 3.802e-05       
#                                           
#                   Kappa : 0.665           
#                                           
#  Mcnemar&#39;s Test P-Value : 0.0455          
#                                           
#             Sensitivity : 0.6327          
#             Specificity : 0.9722          
#          Pos Pred Value : 0.8158          
#          Neg Pred Value : 0.9316          
#               Precision : 0.8158          
#                  Recall : 0.6327          
#                      F1 : 0.7126          
#              Prevalence : 0.1628          
#          Detection Rate : 0.1030          
#    Detection Prevalence : 0.1262          
#       Balanced Accuracy : 0.8024          
#                                           
#        &#39;Positive&#39; Class : 1</code></pre>
</div>
<div id="knn" class="section level3">
<h3>kNN</h3>
<pre class="r"><code># Confusion Matrix and Statistics
# 
#           Reference
# Prediction   0   1
#          0 283  21
#          1  12  36
#                                           
#                Accuracy : 0.9062          
#                  95% CI : (0.8709, 0.9346)
#     No Information Rate : 0.8381          
#     P-Value [Acc &gt; NIR] : 0.0001493       
#                                           
#                   Kappa : 0.6311          
#                                           
#  Mcnemar&#39;s Test P-Value : 0.1637344       
#                                           
#             Sensitivity : 0.9593          
#             Specificity : 0.6316          
#          Pos Pred Value : 0.9309          
#          Neg Pred Value : 0.7500          
#              Prevalence : 0.8381          
#          Detection Rate : 0.8040          
#    Detection Prevalence : 0.8636          
#       Balanced Accuracy : 0.7955          
#                                           
#        &#39;Positive&#39; Class : 0</code></pre>
</div>
<div id="logistic-regression" class="section level3">
<h3>Logistic Regression</h3>
<pre class="r"><code># Confusion Matrix and Statistics
# 
#           Reference
# Prediction   0   1
#          0 282  21
#          1  13  36
#                                           
#                Accuracy : 0.9034          
#                  95% CI : (0.8676, 0.9322)
#     No Information Rate : 0.8381          
#     P-Value [Acc &gt; NIR] : 0.0002803       
#                                           
#                   Kappa : 0.6228          
#                                           
#  Mcnemar&#39;s Test P-Value : 0.2299491       
#                                           
#             Sensitivity : 0.9559          
#             Specificity : 0.6316          
#          Pos Pred Value : 0.9307          
#          Neg Pred Value : 0.7347          
#              Prevalence : 0.8381          
#          Detection Rate : 0.8011          
#    Detection Prevalence : 0.8608          
#       Balanced Accuracy : 0.7938          
#                                           
#        &#39;Positive&#39; Class : 0    </code></pre>
</div>
<div id="decision-tree" class="section level3">
<h3>Decision Tree</h3>
<pre class="r"><code># Confusion Matrix and Statistics
# 
#           Reference
# Prediction   0   1
#          0 243  21
#          1   9  28
#                                           
#                Accuracy : 0.9003          
#                  95% CI : (0.8608, 0.9317)
#     No Information Rate : 0.8372          
#     P-Value [Acc &gt; NIR] : 0.001154        
#                                           
#                   Kappa : 0.5943          
#                                           
#  Mcnemar&#39;s Test P-Value : 0.044610        
#                                           
#             Sensitivity : 0.57143         
#             Specificity : 0.96429         
#          Pos Pred Value : 0.75676         
#          Neg Pred Value : 0.92045         
#               Precision : 0.75676         
#                  Recall : 0.57143         
#                      F1 : 0.65116         
#              Prevalence : 0.16279         
#          Detection Rate : 0.09302         
#    Detection Prevalence : 0.12292         
#       Balanced Accuracy : 0.76786         
#                                           
#        &#39;Positive&#39; Class : 1</code></pre>
</div>
<div id="naive-bayes" class="section level3">
<h3>Naive Bayes</h3>
<pre class="r"><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction Normal COVID19
##    Normal     235      24
##    COVID19     15      26
##                                           
##                Accuracy : 0.87            
##                  95% CI : (0.8266, 0.9059)
##     No Information Rate : 0.8333          
##     P-Value [Acc &gt; NIR] : 0.04857         
##                                           
##                   Kappa : 0.4957          
##                                           
##  Mcnemar&#39;s Test P-Value : 0.20018         
##                                           
##             Sensitivity : 0.52000         
##             Specificity : 0.94000         
##          Pos Pred Value : 0.63415         
##          Neg Pred Value : 0.90734         
##              Prevalence : 0.16667         
##          Detection Rate : 0.08667         
##    Detection Prevalence : 0.13667         
##       Balanced Accuracy : 0.73000         
##                                           
##        &#39;Positive&#39; Class : COVID19         
## </code></pre>
</div>
<div id="support-vector-machine" class="section level3">
<h3>Support Vector Machine</h3>
<pre class="r"><code># 
# Confusion Matrix and Statistics
# 
#           Reference
# Prediction   0   1
#          0  26   0
#          1 307 346
#                                           
#                Accuracy : 0.5479          
#                  95% CI : (0.5096, 0.5858)
#     No Information Rate : 0.5096          
#     P-Value [Acc &gt; NIR] : 0.02506         
#                                           
#                   Kappa : 0.0795          
#                                           
#  Mcnemar&#39;s Test P-Value : &lt; 2e-16         
#                                           
#             Sensitivity : 1.00000         
#             Specificity : 0.07808         
#          Pos Pred Value : 0.52986         
#          Neg Pred Value : 1.00000         
#              Prevalence : 0.50957         
#          Detection Rate : 0.50957         
#    Detection Prevalence : 0.96171         
#       Balanced Accuracy : 0.53904         
#                                           
#        &#39;Positive&#39; Class : 1</code></pre>
<hr />
</div>
</div>
<div id="final-analysis" class="section level2">
<h2>Final Analysis</h2>
<p>Based on our approach, we initially tried to extract the features out of the CXR images without any segmentation. However, we found that the area of interest i.e., the lung area is a very small segment of the whole image. Hence, the noise around the lung area dominates the outcome of the classification. Moreover, we found that quality of CXR images highly affects the feature vectors. For this reason, we segmented the images to find the area of interest and extract our features on corresponding lung-segment. The results were better in that case. However, we could not deal with quality of images in terms of light exposure.</p>
<p>We tried explaining our prediction using <code>LIME</code> image module. Intially, we tried applying LIME on the whole image. However, the results were not good. All the areas highlighted by LIME were outside of lung-portion. So, we tried applying LIME on segmented image by applying black background on the non-lung area hoping that the LIME super-pixels will ignore the black backgrounded regions. We manually confirmed that any perturbed image outside the lung-segment area doesn’t get a different prediction. However, we partially succeded on this approach where we noticed that only the negative COVID images (False Negatives too) were correctly marked by LIME. However, positive images could not be properly annotated by LIME within the area of interest.</p>
<p>We also applied classification algorithms, on benchmark dataset and compared the performaces of simple intrinsically explainable models we used and found that some of the very simple models such as kNN, Naive Bayes and Random Forest are giving high accuracy. To our astonishment, SVM couldn’t perform well in comparsion to these simpler models.</p>
<p>We proposed to work on an ensemble architecture where we use our simpler models to boost our confidence in prediction. However, such an approach couldn’t give us the kind of robustness we expected. Hence, after seeing results with the ensemble approach, we dropped the idea of ensemble classification.</p>
<p>We found Local Binary Pattern to be a powerful texture based descriptor, where the only justification of its usefulness can be seen when we compare our results with Neural Network based approaches in the benchmark section.</p>
<hr />
</div>
<div id="conclusion" class="section level2">
<h2>Conclusion</h2>
<p>We applied intrinsically explainable models and LIME explainer on CXR images, for COVID detection and explaination. The results obtained by the classifiers were of higher accuracy whereas LIME failed to perform the similarly. We observed that LBP are good dicriminatory feature vectors for CXR images, however we cannot mitigate the effect of luminosity, brightness and quality to the images. These factors add bias to our classifiers.</p>
<hr />
</div>
<div id="references" class="section level2 unnumbered">
<h2 class="unnumbered">References</h2>
<div id="refs" class="references">
<div id="ref-ribeiro2016should">
<p>[1] M.T. Ribeiro, S. Singh, C. Guestrin, " Why should i trust you?" Explaining the predictions of any classifier, in: Proceedings of the 22nd Acm Sigkdd International Conference on Knowledge Discovery and Data Mining, 2016: pp. 1135–1144.</p>
</div>
<div id="ref-ozturk2020automated">
<p>[2] T. Ozturk, M. Talo, E.A. Yildirim, U.B. Baloglu, O. Yildirim, U.R. Acharya, Automated detection of covid-19 cases using deep neural networks with x-ray images, Computers in Biology and Medicine. (2020) 103792.</p>
</div>
<div id="ref-cohen2020covid">
<p>[3] J.P. Cohen, P. Morrison, L. Dao, COVID-19 image data collection, arXiv 2003.11597. (2020). <a href="https://github.com/ieee8023/covid-chestxray-dataset">https://github.com/ieee8023/covid-chestxray-dataset</a>.</p>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3,h4",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
