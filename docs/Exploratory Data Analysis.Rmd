---
header-includes:
   - \usepackage{bbm}
always_allow_html: yes

title: "Exploratory Data Analysis"

bookdown::html_document2: default
output:
  html_document:
    df_print: paged
    toc: true
    toc_depth: 4
    toc_float: 
      collapsed: true
      smooth_scroll: true
    theme: yeti
    highlight: default
link-citations: yes
bibliography: references.bib
csl: data-and-knowledge-engineering.csl
---

&nbsp;
&nbsp;
&nbsp;

```{r setup, echo=FALSE}
#setwd("C:\\Users\\jalaj\\Documents\\GitHub\\Data-Science-with-R-Project\\covid-dataset")
load('covid_data_new_masked')
dataset <- covid_data
```



## Dataset:
According to [@Zhao2020COVIDCTDatasetAC; @wang2020deep; @li2020artificial; @karim2020deepcovidexplainer; @singh2020classification] CT-Scan data would be gold-standard for us and also potray pretty good results evaluated in terms of Accuracy and F~1~-Score. However, due to CT Scan being available in very less quantity publicly, we would like to use Chest X-rays as our dataset. Though, it won't be that competible in terms of quality w.r.t CT-Scans but @KERMANY20181122 suggests CXR to be sufficient and comparable to CT-Scans in order to diagnose COVID-19 patients.

In particular we have used the [COVID-19 Dataset-Repo](https://shorturl.at/qwLR0) as our Ground Truth.

[^1]: https://github.com/rezacsedu/DeepCOVIDExplainer
[^2]: https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia
[^3]: https://www.kaggle.com/c/rsna-pneumonia-detection-challenge
[^4]: https://github.com/ieee8023/covid-chestxray-dataset

***

## Exploratory Data Analysis:

### <span class="sub-header">Data Exploration</span>

Real world datasets are mostly imbalanced. The COVID-19 CXR (Chest X-Rays) dataset we used has around 1000 to 313 negative to positive ratio. That there are nearly three times more negative cases than that of positive. The classification algorithms in this case tends to favor the majority class. The distribution of the classes in the dataset in reality refers to the actual class distribution of the covid affected cases. Hence, the learning task in hand is a imbalanced learning task because there are more people with healthy lungs than that of with COVID-19.


There are several methods to deal with this problem in classification setting, where the main objective is to rebalance the distribution by resampling the data to reduce the class imbalance problem, namely oversampling and under sampling. For our purpose we have used k fold cross-validation to train our model, where the data is split into multiple portions, and then (k-1) splits are used for training and 1 split for validation. And then this process is repeated several times.
Our Dataset consists of 313 Positive COVID CXR and 1000 Negative CXR collected from four different sources to make our version of the dataset to work upon. This includes COVIDx dataset of @karim2020deepcovidexplainer[^1], Kaggle CXR Pneumonia dataset by Paul Mooney [^2], CXR images of adult subjects from the RSNA Pneumonia Detection Challenge [^3], original and augmented versions of COVID-19 examples [^4] from @cohen2020covid. 

The image below is an instance of COVID negative image. The figure above shows an instance of a COVID-19 negative images. Similar to this image, all the images in the dataset are in Standard RGB color space. The dataset contains files in `.jpg`, `.jpeg` and `.png` formats. All the files are standardised to `.png` format for the ease of further processing.
``` {r cropped, echo=FALSE, warning=FALSE, message=FALSE, fig.align = 'center'}
library(magick)
covid.neg <- image_read('C:/Users/jalaj/Documents/DataSci with R/Project Files/covid-dataset/covid-negative/1.jpg')
print(covid.neg)
```


These are 1000 COVID-19 negative and 313 COVID-19 positive CXR images. This shows a high skew towards positives in the dataset just for the reason of less availability of negatives in comparision to positives. 
```{r distribution_plot, echo=FALSE, message=FALSE, warning=FALSE, fig.align = 'center'}
library(ggplot2)
qplot(covid_data$V59, binwidth=0.1, main = 'Data Distribution Histogram', xlab = 'Target Variable', ylab = 'Number of Samples')
```


The figure above shows the skewness of the distribution of the data. The plot states the frequency of the positive and negative images in the dataset. Here, for the interpretation; 0 is taken as COVID negative and 1 as COVID positive. The figure delineates the ratio of images as being approx. 3:1. This signifies the data being skewed towards the positive instances.


``` {r data-frequency, echo=FALSE, message=FALSE, warning=FALSE, fig.align = 'center'}
library(funModeling)
freq(covid_data$V59)
```

Pie chart is the simplest representation of the dataset. This shows amount of images in percentage.
``` {r pie-chart, echo=FALSE, message=FALSE, warning=FALSE, fig.align = 'center'}

mytable <- table(covid_data$V59)
lbls <- c("0", "1")
piepercent<- round(100*mytable/sum(mytable), 1)
pie(mytable, labels =  piepercent, col=rainbow(length(lbls)), main = "Percentage of positives and negatives")
```



### <span class="sub-header">Data Pre-processing</span>

The raw images are fed into the Local Binary Pattern Algorithm. The Algorithm takes the images and resizes into 256*256 height to width format.

```{r resizing, echo=FALSE, message=FALSE, warning=FALSE, fig.align = 'center'}
scaled <- image_scale(covid.neg, "256x256")
print(scaled)
```

### <span class="sub-header">Feature Extraction</span>
For CXR images, the visual attribute that shows the most promising results are the texture based descriptors. There are several texture based descriptors that are available, both handcrafted and non handcrafted, however, we have focused mostly on the widely used Local Binary Patterns, formularized by [@ojala1996comparative].


LBP is a powerful texture descriptor, that has been applied on several classification tasks involving the texture. The LBP is calculated on a pixel to pixel basis by considering a center pixel(c) and its neighbourhood pixels (n) with some radius. Each neighbour pixel n is compared with center pixel c by means of substracting the grey values say g(c) and g(n)  to get a distance d, such that if the d is negative then 0 is substituted in the place of the neighbour pixel else 1.

$$d = 1~~iff~~g(c)-g(n)â‰¥0$$
$$d=0~otherwise$$

The descriptor is then the histogram of such which counts the occurrence of binary pattens. The histogram depends on the setup of the radius and the obviously the pixel neighborhood. LBP has been successfully tried on several classification techniques [@paula2014forest]

**Parameters:** Parameters used for the purpose are LBP ~8,2~ with 58 dimensions. The details of the parameters can be found in [@ojala1996comparative].

**Vectors:** As is previously explained there are total of 58 dimensions, to the descriptor. For a given CXR image we initially ran the descriptor on the complete image, and thus the descriptors obtained were very rich.

However, with this setting there is a problem, that the CXR image not only captures the area of the lungs but the whole rib cage, which includes other organs too. Hence there is much noise considering out aim of getting the features our of the are of the lungs. For that purpose we used [segmentations](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/), to segment the area of the lungs our by means of a mask and then calculate the LBP for the masked area.

```{r resize, echo=FALSE, message=FALSE, warning=FALSE, fig.align = 'left'}
print(scaled)
```
<center>
![1.jpgtmp.png](1.jpgtmp.png)  ![1-mask.png](1-mask.png)
</center>

As expected in this case, the figure below shows some of the bins of the histogram are empty due to the usage of masking of the image.

![Histogram of Image after LBP](Histogram_after_lbp.png)

All the images are converted into grayscale because the Local Binary Pattern works only with grayscale images.

```
img <- grayscale(img)
```

The Algorithm converts the images into a data matrix and feds it into local binary function which creates the lbp vectors for the corresponding image.

```
imgm <- data.matrix(img)
lbpd <- lbp(imgm, 2)
```

Thereafter, it forms a dataframe of 1313 rows and 59 columns where 59th column being the Target Class with values `0` for COVID negatives and `1` for COVID positives.
```{r data-explorer, echo=FALSE, warning=FALSE, message=FALSE, fig.align = 'center'}
library(DataExplorer)
#DataExplorer::create_report(data)
introduce(dataset)
plot_intro(dataset)
```


The figure below shows the structure of the data frame.
```{r fram-struct, echo=FALSE, warning=FALSE, message=FALSE, fig.align = 'center'}
plot_str(dataset)
```

Since the real world data can be messy, the following plot below shows the missing values in columns. All the columns are kept nameless and are therefore by default named **"V#"** with its repective column number.

```{r plot, echo=FALSE, warning=FALSE, message=FALSE, fig.align = 'center'}
plot_missing(dataset)
```


The figures below shows column-wise vector representation:
``` {r bar, echo=FALSE, warning=FALSE, message=FALSE, fig.align = 'center'}
plot_bar(dataset$V59)

```

The following plot shows visualisation of distribution of lbp vector column-wise:
```{r hist, echo=FALSE, warning=FALSE, message=FALSE, fig.align = 'center'}
plot_histogram(dataset)
```


The figure below shows that very few columns vectors appears to be correlated. This is the case because the data has been masked.
``` {r bar1, echo=FALSE, warning=FALSE, message=FALSE, fig.align = 'center'}
plot_correlation(na.omit(dataset))
```

The figure shows Quantile-Quantile plot showing distribution of all the columns compared to normal distribution.
``` {r qq-plot, echo=FALSE, warning=FALSE, message=FALSE, fig.align = 'center'}
plot_qq(dataset, sampled_rows = 1000L)
```


The following shows the variance in percentage for all the lbp vectors by **Principal Component Analysis**.
``` {r scatter, echo=FALSE, warning=FALSE, message=FALSE, fig.align = 'center'}
pca_df <- na.omit(dataset)
plot_prcomp(pca_df, variance_cap = 0.9, nrow = 2L, ncol = 2L)
```


***

# Model {.tabset}

## kNN

K-Neigherst Neighbour is one of the models used for classification. kNN has been successfully used in tasks where texture-based descriptors are used [@sorensen2008texture]. In kNN classification, we expect that the classifier will examine the k nearest neighbors and return the class labels associated with the majority of k nearest neighbor. The accuracy of the model depends heavily on k, i.e. the number of nearest neighbors to consider for classification purpose. So, each neighbor adds a vote or a confidence towards the classification of a query instance. We use this model, in hope that the features extracted above captures the specific discriminatory properties of the lung area and on similar note the nearest neighbors will capture the same properties. 

### Parameters and Settings 

We initially split the data by a proportion of 30:70 distributed among both the classes for test and training purpose.
You can also embed plots, for example:

```{r libraries, results='hide', warning = FALSE, message=FALSE}

library(caret)
library(ggplot2)
library(wvtool)
library(imager)
library(ROSE)
```

```{r wd, echo=FALSE}
load("covid_data_new_masked")
glass.df = covid_data
```


```{r pre-process, echo=TRUE}
# all the independent variables are numbers
# we will convert the type variable which is the response variable as factor
glass.df$V59<- as.factor(glass.df$V59) # 7 labels

# training and test data 70:30
set.seed(123)
ind = sample(2, nrow(glass.df), replace = TRUE, prob=c(0.7,0.3))
train.df = glass.df[ind == 1,]
test.df = glass.df[ind == 2,]
```


For training, to tackle the class imbalance problem and we use 10 cross validation with 3 repeats. That is data will be split entirely 3 times, and for each of the 3 times, 10-fold cross validation is done for validation.

``` {r echo=TRUE}
trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
```

For evaluation of K, we decide at train time, the number that gives the highest accuracy. In our case, k=9 gave us the best accuracy.
``` {r results='hide', warning = FALSE, message=FALSE}

knn_fit <- train(V59 ~., data = train.df, method = "knn",
                 trControl=trctrl,
                 preProcess = c("center", "scale"),
                 tuneLength = 15)

```


```{r}

summary(knn_fit)
plot(knn_fit)

```
The pipeline of KNN model we use, additionally centers and scales the data. The unseen instances are also subject to the same fit.


We also use a setting where the response is not a discrete  positive or negative output but, gives the prediction confidence(probability) of the classifier for both of the classes.


**Results:** We test the model with the test data that was initially split out from the overall dataset

``` {r prediction, echo = TRUE}
test_pred <- predict(knn_fit, newdata = test.df)
summary(test_pred)
confusionMatrix(test_pred, test.df$V59)
roc.curve(test.df$V59, test_pred, plotit = T)
```
## SVM with Rbf kernel

(tab content)

## Logitistic Regression

(tab content)

## Random Forest

(tab content)

### Decision Trees

(tab content)

## Naive Bayes

(tab content)


# References