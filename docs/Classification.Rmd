---
header-includes:
   - \usepackage{bbm}
always_allow_html: yes
title: "Classification"

bookdown::html_document2: default
output:
  html_document:
    df_print: paged
    toc: true
    toc_depth: 4
    toc_float: 
      collapsed: true
      smooth_scroll: true
    theme: yeti
    highlight: default
link-citations: yes
bibliography: references.bib
csl: data-and-knowledge-engineering.csl
references:
- id: WHO
  title: Novel Coronavirus – China 2020
  author:
  - family: World Health Organisation
  URL: 'https://www.who.int/csr/don/12-january-2020-novel-coronavirus-china/en/'
  issued:
    year: 2020
    month: 1

---

&nbsp;
&nbsp;
&nbsp;
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Data-Set

Our dataset is a collection of 1313 CXR images containing COVID-19 positive and negative samples. There is a problem of class imbalance as we had 1000 negative samples compared to only 313 positive samples. The local binary patterns that we extracted from the CXR images have 58 dimensions. For class imbalance, we have implemented an oversampling technique that is provided by the R package ‘ROSE’, which basically means Random Over Sampling Examples. It’s a resampling function that generates synthetic balanced samples using holdout, bootstrap or cross-validation methods. After oversampling our dataset consisted of 1000 negative and 1031 positive examples.

```{r Random Forest, include=FALSE}


load('covid_data_new_masked')

data = covid_data

#Setting V59 as factor variable as that is the target
data$V59 <- as.factor(data$V59)
summary(data)

#Split Dataset to train and test
set.seed(123) # Set Seed so that same sample can be reproduced in future also
# Now Selecting 75% of data as sample from total 'n' rows of the data  
sample <- sample.int(n = nrow(data), size = floor(.75*nrow(data)), replace = F)
train <- data[sample, ]
test  <- data[-sample, ]
```

```{r plots}

#Visualizing distribution of each class
barplot(prop.table(table(covid_data$V59)),
        col = rainbow(2),
        ylim = c(0,1),
        main = "Class Distribution")
barplot(prop.table(table(train$V59)),
        col = rainbow(2),
        ylim = c(0,1),
        main = "Class Distribution")
barplot(prop.table(table(test$V59)),
        col = rainbow(2),
        ylim = c(0,1),
        main = "Class Distribution")

#Training Models
library(randomForest)
library(rpart)
library(rpart.plot)
#Random Forest
rftrain <- randomForest(V59~.,data = train)
#Decision Tree
dttrain <- rpart(V59~.,data = train, method = "class")
dttrain_criteria <- rpart(V59~.,data = train, method = "class", minsplit = 20, minbucket = 10)
rpart.plot(dttrain)
rpart.plot(dttrain_criteria)
```

## Random Forest

Random forest is one of the algorithms we tried to apply on the lbp features that was extracted from the X-ray images. The implementation was done through the ‘randomForest’ package that is available in R. The package uses Breiman’s method of random forests for classification. But this package has the flexibility to be applied in a regression problem as well. In the default parameter setting, the no. of trees that the algorithm learns is 200. With that, we achieved an accuracy of about 89.67% with an F1 score of 0.74 in our dataset. The area under the ROC curve in this case was 0.802. On the over-sampled data, the accuracy dropped to 81.84% with an F1 score of 0.78. The area under the ROC curve in this case is 0.819.


You can also embed plots, for example:

```{r pressure, echo=FALSE}
#Evaluation with test
library(caret)
confusionMatrix(predict(rftrain, test), test$V59, positive = '1', mode = "everything")
confusionMatrix(predict(object=dttrain,test,type="class"), test$V59, positive = '1', mode = "everything")
confusionMatrix(predict(object=dttrain_criteria,test,type="class"), test$V59, positive = '1', mode = "everything")


#Under Sampling
library(ROSE)
under_train = ovun.sample(V59~., data = train, method = "under", N = 294)$data
table(under_train$V59)
under_test = ovun.sample(V59~., data = test, method = "under", N = 100)$data
table(under_test$V59)

barplot(prop.table(table(under_train$V59)),
        col = rainbow(2),
        ylim = c(0,1),
        main = "Class Distribution")
barplot(prop.table(table(under_test$V59)),
        col = rainbow(2),
        ylim = c(0,1),
        main = "Class Distribution")

library(randomForest)
rftrain_under <- randomForest(V59~.,data = under_train)
dttrain_under <- rpart(V59~.,data = under_train, method = "class")
rpart.plot(dttrain_under)

#Evaluation with test
library(caret)
confusionMatrix(predict(rftrain_under, under_test), under_test$V59, positive = '1')
confusionMatrix(predict(object=dttrain_under,under_test,type="class"), under_test$V59, positive = '1')

#Over Sampling
library(ROSE)
over_train = ovun.sample(V59~., data = train, method = "over", N = 1500)$data
table(over_train$V59)
over_test = ovun.sample(V59~., data = test, method = "over", N = 502)$data
table(over_test$V59)

barplot(prop.table(table(over_train$V59)),
        col = rainbow(2),
        ylim = c(0,1),
        main = "Class Distribution")
barplot(prop.table(table(over_test$V59)),
        col = rainbow(2),
        ylim = c(0,1),
        main = "Class Distribution")

library(randomForest)
rftrain_over <- randomForest(V59~.,data = over_train)
dttrain_over <- rpart(V59~.,data = over_train, method = "class")
dttrain_over_criteria <- rpart(V59~.,data = train, method = "class", minsplit = 20, minbucket = 10)
rpart.plot(dttrain)
rpart.plot(dttrain_over_criteria)
rpart.plot(dttrain_over)
```

## Decision Trees

For decision trees, we used the R library ‘rpart’ which is generally used to learn classification or regression trees. We ran this algorithm in its default setting (minsplit = 20 and minbucket = round(minsplit/3)) where minsplit is the minimum number of observations that must exist in a node for a split to occur and min bucket is the minimum number of observations in any leaf node. The accuracy that we obtained on the original dataset was 85.71% with an F1 score of 0.67. The area under the ROC curve in this case is 0.772. In the over-sampled dataset, the accuracy dropped to 74.49% with 0.72 as F1 score. The area under the ROC curve also dropped to 0.732.


```{r}
library(caret)
confusionMatrix(predict(rftrain_over, over_test), over_test$V59, positive = '1', mode = "everything")
confusionMatrix(predict(object=dttrain_over,over_test,type="class"), over_test$V59, positive = '1', mode = "everything")
confusionMatrix(predict(object=dttrain_over_criteria,test,type="class"), test$V59, positive = '1', mode = "everything")
```