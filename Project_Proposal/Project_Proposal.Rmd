---
title: "Data Science with `R` Project Proposal"
author: "Team: COVID-19 Predictor"
date: "20.05.2020"
output: html_document
#bibliography: bibliography.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Project Title: COVID-19 Prediction using Explainable Machine Learning


## Background and Motivation:

The COVID-19 or the SARS-COV2 originated from the district of Wuhan, China has transpired to be a pandemic worldwide. Research on the COVID-19 is a hot topic among the Artificial Intelligence community recently. Due to shortage and limited efficiency of current testing mechanism of COVID-19 tests, through RT-PCR kits [^1], it fits in-line with our motivation towards building a classifier that predicts the presence or absence of COVID-19 in a patient from chest X-Ray images. In addition to current research, our work tries to finds insights of COVID-19 detection using simpler explainable models and effectively use the research surrounding the virus.

[^1]: https://arxiv.org/abs/2003.13865

***

## Ground Truth and Technology Stack:

### Technology Stack
The project will be built in `R` with usage of API’s like `magick`, `opencv` for image processing and `tidyverse` packages like `dplyr` and `tidyr` for data manipulation, `ggplot2` for data visualization, `rmarkdown` and `knitr` for reproducible & automated reporting, `shiny` for interactive web applications, and `tidymodels` for inferential and predictive modeling.

### Dataset
Our approach to learn would be from chest X-Rays however, as literature surveys suggest, CT-scans transfer much knowledge and thus is better suitable Deep Learning based approaches, X-Rays on the other hand are publicly available and abundant source than CT-scans and gives good results on the fronts of vision tasks. Both Deep Learning based approaches and features extraction using computer vision will be done from them. We will for reasons of abundance of data stick to X-Ray images.In particular we will use the [Dataset](https://github.com/rezacsedu/DeepCOVIDExplainer) as our Ground Truth.

***

## Data Science Pipeline Design Overview:

The proposal describes categorically the following points, viz. the feature extraction and selection areas, models that are to be used, fusion techniques that can be employed, overall architecture of the system to be built.

### Feature Extraction and Selection
For the part of feature extraction, we shall try texture-based descriptors. There exist several texture-based vision algorithms. We might combine features before training and train our model on a combined feature set. Or we can train models on individual features, and then combine prediction results might be combined and thus one feature might only not be selected but multiple features can be selected. <br>
Literature survey tells us Local Binary Patterns shall be a good choice for texture-based descriptor. We may also try to use pretrained networks to gain texture descriptors or vision API’s for the extraction part. <br>
Moreover, there are several neural nets we faced in literature survey, that are carefully curated for the purpose of the COVID-19, which requires the image to directly fed to the net, and thereby auto encodes the parameters.

### Models to train and aim of the project
The problem in hand is a classification problem where we can either classify an image as positive or negative. Here we would like to emphasize that the model won’t predict presence or absence or pneumonia, which is a result not only of COVID-19 but other kind of reasons also affect this. <br>

We mainly will try two kinds of algorithms:

1. One that can be trained based on features to be extracted, like clustering, SVM, binary classification (regression). Mostly because the models are intrinsically explainable.

2. Neural Net based approaches, where the model is a black box model, and we use tools like saliency maps for description.

### Overview of Design

![](Picture1.png)

The overall architecture of the system is like the above… where we have images and we extract features from them or do certain preprocessing such as cropping of image etc. Then the features or preprocessed images are fed to the classifier for training. Once trained unknown instance is supplied for classification. We will use late fusion; hence we cumulate the prediction of each of the classifier with certain confidence. The confidence shall be extracted by calculating the MAP score. The Map score can be calculated on a test set that shall be segregated from the overall dataset before the training phase begins. The ratio of the MAP score shall give the confidence contribution of each of the systems.

## Evaluation and Visualization

### Evaluation

Evaluation Metrics are used to calculate the performance of the model. We have different type of evaluation methods but selecting a metric is an important step in the project. Most commonly used metrics are Precision and Recall. Precision and Recall are also used with other metrics like Accuracy, F1-Score, Area under ROC curve, MAP Score.
The higer the metric value the better the performance.

Accuracy: Best and mostly used metric. Easily suited for binary as well as multiclass classification problem.
$$\ Accuracy = Number~of~corrected~predictions~/~Total~number~of~predictions $$
$$\ Accuracy = (TP+TN) / (TP+TN+FP+FN) $$

Precision: It is a best choice when we want to be very sure of our prediction.
$$\ Precision = TP / TP+FP $$

Recall: Captures as many positives as possible
$$\ Recall = TP / TP+FN $$

F~1~-Score: It is a weighted average between Precision and Recall.

$$\ F_1~Score = 2 * (Precision*Recall) / (Precision+Recall) $$


MAP score: Quantifies how good our model at performing the query. First we calculate the average of the precision for each query and then the mean of all these AP scores.

Q – No.of queries in the set 

AveP(q) – Average pecision for a each query q

$$\sum_{q=1}^{Q} AveP(q)/Q $$

AUC ROC: Indicates how well the probabilities from the positive classes are separated from the negative classes. Mostly used to check or visualize the performance of the multi-class classification models. ROC is the probability curve and AUC represents degree or measure of separability.


### Visualization
Visualization is a computer generated image using a computer representation of data as primary source and a human as its primary targets. It's an abstract of information.
Box Plot easily display data and we can see outliers as well. It graphically displays the data in five statistics Minimum quartile, 25th or lower quartile, 50th or median quartile, 75th or upper quartile and the maximum quartile, which summarizes the distribution of dataset.

***

## Time Plan:

**2 Meetings per week. Tuesday and Friday at 17:30 Sharp!**

```{r echo = FALSE, results='asis'}

d<-data.frame(Sr.Nr.= c(1,2,3),
              Work_Slot=c(1,2,3), 
              Time_Period=c('22.05.2020 - 05.06.2020','05.06.2020 - 19.06.2020','19.06.2020 - 03.07.2020'),
              Tasks=c("Data-Preprocessing","Modeling","Evaluation"),
              Member_Name=c('Jalaj, Subhankar','Subhajit, Shivam','Roshmitha'))
library(knitr)

kable(d, row.names = NA, col.names = NA,  align = "lll", caption = "A Sample Table")
```

***
### Team:

##### **Jalaj, Vora** 
M.Sc. Digital Engineering <br>

##### **Shivam, Singh**
M.Sc. Digital Engineering <br>

##### **Subhankar, Patra**
M.Sc. Data and Knowledge Engineering <br>

##### **Subhajit, Mondal**
M.Sc. Data and Knowledge Engineering <br>

##### **Roshmitha, Thummala**
M.Sc. Data and Knowledge Engineering <br>


***Supervised by:*** Uli Niemann
